<!DOCTYPE html>
<html lang="en-us">
  <head>
    
    <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="generator" content="Hugo 0.74.3 with theme Tranquilpeak 0.4.8-BETA">
<meta name="author" content="Yimeng Chen">
<meta name="keywords" content="Mutual Information, Contrastive, Causality">
<meta name="description" content="A survey.">


<meta property="og:description" content="A survey.">
<meta property="og:type" content="article">
<meta property="og:title" content="Representation Learning">
<meta name="twitter:title" content="Representation Learning">
<meta property="og:url" content="https://beastlyprime.github.io/representation-learning/">
<meta property="twitter:url" content="https://beastlyprime.github.io/representation-learning/">
<meta property="og:site_name" content="Yimeng Chen&#39;s site">
<meta property="og:description" content="A survey.">
<meta name="twitter:description" content="A survey.">
<meta property="og:locale" content="en-us">

  
    <meta property="article:published_time" content="2020-08-02T00:00:00">
  
  
    <meta property="article:modified_time" content="2020-08-02T00:00:00">
  
  
  
    
      <meta property="article:section" content="survey">
    
  
  
    
      <meta property="article:tag" content="Mutual Information, Representation Learning">
    
  


<meta name="twitter:card" content="summary">







  <meta property="og:image" content="https://beastlyprime.github.io/images/GWsmall.jpg">
  <meta property="twitter:image" content="https://beastlyprime.github.io/images/GWsmall.jpg">





  <meta property="og:image" content="https://beastlyprime.github.io/images/author.jpg">
  <meta property="twitter:image" content="https://beastlyprime.github.io/images/author.jpg">


    <title>Representation Learning</title>

    <link rel="icon" href="https://beastlyprime.github.io/favicon.png">
    

    

    <link rel="canonical" href="https://beastlyprime.github.io/representation-learning/">

    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css" integrity="sha256-eZrrJcwDc/3uDhsdt61sL2oOBY362qM3lon1gyExkL0=" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/2.1.4/jquery.fancybox.min.css" integrity="sha256-vuXZ9LGmmwtjqFX1F+EKin1ThZMub58gKULUyf0qECk=" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/2.1.4/helpers/jquery.fancybox-thumbs.min.css" integrity="sha256-SEa4XYAHihTcEP1f5gARTB2K26Uk8PsndQYHQC1f4jU=" crossorigin="anonymous" />
    
    
    <link rel="stylesheet" href="https://beastlyprime.github.io/css/style-twzjdbqhmnnacqs0pwwdzcdbt8yhv8giawvjqjmyfoqnvazl0dalmnhdkvp7.min.css" />
    
    

    
      
    
    
  </head>

  <body>
    <div id="blog">
      <header id="header" data-behavior="1">
  <i id="btn-open-sidebar" class="fa fa-lg fa-bars"></i>
  <div class="header-title">
    <a class="header-title-link" href="https://beastlyprime.github.io/">Yimeng Chen&#39;s site</a>
  </div>
  
    
      <a class="header-right-picture "
         href="https://beastlyprime.github.io/#about">
    
    
    
      
        <img class="header-picture" src="https://beastlyprime.github.io/images/author.jpg" alt="Author&#39;s picture" />
      
    
    </a>
  
</header>

      <nav id="sidebar" data-behavior="1">
  <div class="sidebar-container">
    
      <div class="sidebar-profile">
        <a href="https://beastlyprime.github.io/#about">
          <img class="sidebar-profile-picture" src="https://beastlyprime.github.io/images/author.jpg" alt="Author&#39;s picture" />
        </a>
        <h4 class="sidebar-profile-name">Yimeng Chen</h4>
        
          <h5 class="sidebar-profile-bio">A bird in the forest of AI.</h5>
        
      </div>
    
    <ul class="sidebar-buttons">
      
  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://beastlyprime.github.io/">
    
      <i class="sidebar-button-icon fa fa-lg fa-home"></i>
      
      <span class="sidebar-button-desc">Home</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://beastlyprime.github.io/categories">
    
      <i class="sidebar-button-icon fa fa-lg fa-bookmark"></i>
      
      <span class="sidebar-button-desc">Categories</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://beastlyprime.github.io/tags">
    
      <i class="sidebar-button-icon fa fa-lg fa-tags"></i>
      
      <span class="sidebar-button-desc">Tags</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://beastlyprime.github.io/archives">
    
      <i class="sidebar-button-icon fa fa-lg fa-archive"></i>
      
      <span class="sidebar-button-desc">Archives</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://beastlyprime.github.io/#about">
    
      <i class="sidebar-button-icon fa fa-lg fa-question"></i>
      
      <span class="sidebar-button-desc">About</span>
    </a>
  </li>


    </ul>
    <ul class="sidebar-buttons">
      

    </ul>
    <ul class="sidebar-buttons">
      
  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://beastlyprime.github.io/index.xml">
    
      <i class="sidebar-button-icon fa fa-lg fa-rss"></i>
      
      <span class="sidebar-button-desc">RSS</span>
    </a>
  </li>


    </ul>
  </div>
</nav>

      

      <div id="main" data-behavior="1"
        class="
               hasCoverMetaIn
               ">
        <article class="post" itemscope itemType="http://schema.org/BlogPosting">
          
          
            <div class="post-header main-content-wrap text-center">
  
    <h1 class="post-title" itemprop="headline">
      Representation Learning
    </h1>
  
  
  <div class="postShorten-meta post-meta">
    
      <time itemprop="datePublished" datetime="2020-08-02T00:00:00Z">
        
  August 2, 2020

      </time>
    
    
  
  
    <span>in</span>
    
      <a class="category-link" href="https://beastlyprime.github.io/categories/survey">survey</a>
    
  

  </div>

</div>
          
          <div class="post-content markdown" itemprop="articleBody">
            <div class="main-content-wrap">
              <p>A survey.</p>
<h2 id="what-is-representations">What is representations?</h2>
<blockquote>
<p>Any function of the data which is useful for a task. &mdash;- <a href="https://alexachi.github.io/index.html">Alessandro Achille</a></p>
</blockquote>
<p>What is a good representation?</p>
<p>Think about dimension reduction: input; representation space; hypothesis space</p>
<p>The Minimality, Necessary and Information criterion proposed by <em>Ian Fischer</em>:</p>
<ul>
<li>Information: representation Z captures <em>useful</em> information about (X, Y)</li>
<li>Necessity (sufficiency): the information captured by Z should be necessary to solve the task. Can be defined as I(X; Y) &lt;= I(Y; Z).</li>
<li>Minimality: require one that retains the smallest amout of information. I(X; Y) &gt;= I(X; Z)</li>
</ul>
<p>When considering distribution shift, we require an additional Invariance  criterion:</p>
<ul>
<li>Invariance: for any distribution $\mathbb{P}, \mathbb{P}&lsquo;$ of $(X,Y)$, the predictability of $Z$ towards $Y$ is invariant, i.e. $\mathbb{P}(Y|Z)=\mathbb{P}'(Y|Z)$.</li>
</ul>
<h2 id="problem-of-generalization">Problem of Generalization</h2>
<p>The generalization error of model $\hat{f}$ is defined as $\mathcal{R}(\hat{f}) - \inf_{f \in \mathcal{F}} \mathcal{R}(f)$ , where $\mathcal{R}$ denotes the expected loss. The error can be further decomposed into three parts. The first one is the optimization loss $\epsilon_{opt} :=\hat{\mathcal{R}}(\hat{f}) - \inf_{f \in \mathcal{F}_{\delta}} \hat{\mathcal{R}}(f)$, i.e. the loss in optimizing $\hat{f}$ in $\mathcal{F}_\delta$ . The second one is $\epsilon_{stat}:= \mathcal{R}(\hat{f}) - \hat{\mathcal{R}}(\hat{f})$, which is the difference between the empirical and real losses. The last one is the theoretical error induced by the limitation of $\mathcal{F}_\delta$ .</p>
<p>Study on robustness and generalization mostly concerns $\epsilon_{stat}$.  Suppose $\hat{f}(x) = \hat{f} \circ \hat{g}(x) = \hat{f}(\hat{z}) $ .  Generally,  the problem occurs when $\hat{\mathcal{R}}_{train}(\hat{f})$ and $\hat{\mathcal{R}}_{test}(\hat{f})$ have large difference. Such difference orginates from the fact that $\hat{\mathbb{P}}_{train}$ is a partial sampling of the real $\mathbb{P}$.</p>
<p>Robustness and out-of-distribution generalization consider different kinds of distribution shift. We can view the input as a original form of representation. From this view, the robustness and bias-shift can be unified as studies on distribution shift in different representation space.</p>
<p>Similar to that, outlier detection and</p>
<h2 id="some-concepts">Some Concepts</h2>
<p>Rademacher complexity: a measure of the richness of a class of real-valued functions. Unlike VC dimension, Rademacher complexity is not restricted to binary functions, and is related with the data distribution.</p>
<hr>
<h2 id="related-works">Related Works</h2>
<h3 id="1-representation-learning-via-invariant-causal-mechanisms-iclr-2021">1 Representation Learning via Invariant Causal Mechanisms, ICLR 2021</h3>
<h4 id="motivation">Motivation</h4>
<p>(Tschannen et al., 2019) has shown that performance on downstream tasks may be more tightly correlated with the choice of encoder architecture than the achieved MI bound, highlighting <strong>issues with the MI theory of contrastive learning</strong>.</p>
<p>Further, contrastive approaches compare different views of the data (usually under different data augmentations) to calculate similarity scores. This approach to computing scores has been <strong>empirically observed</strong> as a key success factor of contrastive methods, but <strong>has yet to be theoretically justified</strong>. This lack of a solid theoretical explanation for the effectiveness of contrastive methods <strong>hinders their further development</strong>.</p>
<p>To <strong>remedy the theoretical shortcomings</strong>, we analyze the problem of self-supervised representation learning through <strong>a causal lens</strong>:</p>
<ul>
<li>
<p>Formalize intuitions about the data generating process using a causal graph</p>
</li>
<li>
<p>Leverage causal tools to derive properties of the optimal representation. We show that a representation should be an <em>invariant predictor</em> of proxy targets under interventions on features that are only correlated, but not causally related to the <strong>downstream targets of interest</strong>.</p>
</li>
</ul>
<h4 id="contributions">Contributions</h4>
<ul>
<li>
<p>We <strong>formalize</strong> problem of self-supervised representation learning using <strong>causality</strong> and propose to more effectively leverage data augmentations through invariant prediction.</p>
</li>
<li>
<p>We propose a regularizer which explicitly enforces that the prediction of the proxy targets is <strong>invariant across data augmentations (as interventions)</strong>. This gives rise to an objective for self-supervised learning we call Representation Learning via Invariant Causal Mechanisms (RELIC). We write this objective as ![image-20210302152234056](/Users/chenyimeng/Library/Application Support/typora-user-images/image-20210302152234056.png)</p>
</li>
</ul>
<p>![image-20210302151301525](/Users/chenyimeng/Library/Application Support/typora-user-images/image-20210302151301525.png)</p>
<p>![image-20210302151927059](/Users/chenyimeng/Library/Application Support/typora-user-images/image-20210302151927059.png)</p>
<p>![image-20210302160156986](/Users/chenyimeng/Library/Application Support/typora-user-images/image-20210302160156986.png)</p>
<ul>
<li>We show how <strong>this explicit invariance regularization</strong> leverages augmentations <strong>more effectively</strong> than previous self-supervised methods and that representations learned using RELIC are <strong>guaranteed to generalize well</strong> to downstream tasks under <strong>weaker assumptions</strong> than those required by previous work.
<ul>
<li>The explicit invariance penalty encourages the within-class distances (for a downstream task of inter- est) of the representations learned by RELIC to be tightly concentrated.</li>
<li>Theoretical justification for using an instance discrimination-based contrastive loss using a causal perspective.</li>
<li>Minimizing the contrastive loss alone (i.e. α = 0) does not guarantee generalization. Instead, invariance across augmentations must be explicitly enforced.</li>
</ul>
</li>
<li>We generalize contrastive learning using refinements and show that <strong>learning on refinements</strong> is a sufficient condition for learning useful representations; this provides an alternative explanation to MI for the success of contrastive methods, namely that of <strong>causal refinements</strong> of downstream tasks.
<ul>
<li>Invariant under interventions for the refinements &ndash;&gt; invariant under downstream tasks. Straight forward, because it is only addition.</li>
<li>Is the notion &ldquo;refinement&rdquo; has any connection with causality?</li>
<li>Real world data often includes rich sources of metadata which can be used to guide the construction of refinements by grouping the data according to any available meta-data.</li>
</ul>
</li>
</ul>
<h4 id="remark">Remark</h4>
<p>I slightly agree with the idea that &ldquo;there is in fact no causal language needed for this paper&rdquo;. as remarked by <em>AnonReviewer5</em> in ICLR2021.  In my view, the key idea of the paper is the idea of <em>refinement</em>, which is a concept has less connnection with causality. However, I believe the idea of invariance of conditionals is motivated from theory of causality. It is not novel, as similar idea has been proposed in papers like &ldquo;Conditional Variance Penalties and Domain Shift Robustness&rdquo;, but the application to contrastive representation learning makes sense. The organization and writing of this paper is worth to learn.</p>
<h3 id="2-a-theoretical-analysis-of-contrastive-unsupervised-representation-learning-icml-2019">2 A Theoretical Analysis of Contrastive Unsupervised Representation Learning, ICML 2019</h3>
<p>This paper proposes a new concept: <strong>latent classes</strong>, to formalize the notion of <strong>semantic similarity</strong>.</p>
<p><em>Let</em> $\mathcal{C}$ <em>denote the set of all latent classes. Associated with each class</em> $c \in \mathcal{C}$ <em>is a probability distribution</em> $\mathcal{D}<em>c$ <em>over</em> $\mathcal{X}$. These latent classes can overlap arbitrarily: an image of a dog by a tree can appear in both $\mathcal{D}</em>{dog}$ &amp; $\mathcal{D}_{tree}$. Assume a distribution $\rho$ over the classes that characterizes how these classes naturally occur in the unlabeled data.</p>
<p>Semantic similarity of two data points:
positive pair: i.i.d. draws from the same class distribution $\mathcal{D}_c$ for some class $c$ picked randomly according to $\rho$.
negative sample: from the marginal</p>
<p>Assumption: the classes in downstream tasks and their associated data distributions $\mathcal{D}_c$ are the same as in the unlabeled data.</p>
<h3 id="3-learning-explanations-that-are-hard-to-vary-iclr-2021">3 Learning Explanations That Are Hard To Vary, ICLR 2021</h3>
<p>Multiple environments - infer a function $f$ (mechanism)</p>
<p>When do we <em>not</em> learn invariances? &ndash; the rate at which different patterns are learned. Can be improved by</p>
<ul>
<li>Careful architecture design &ndash; hardcoding some invariance in the model architecture</li>
<li>Pretraining &ndash; strong features already emerged and can be readily selected</li>
</ul>
<h3 id="4-on-mutual-information-maximization-for-representation-learning">4 On Mutual Information Maximization for Representation Learning</h3>
              
            </div>
          </div>
          <div id="post-footer" class="post-footer main-content-wrap">
            
              
                
                
                  <div class="post-footer-tags">
                    <span class="text-color-light text-small">TAGGED IN</span><br/>
                    
  <a class="tag tag--primary tag--small" href="https://beastlyprime.github.io/tags/mutual-information-representation-learning/">Mutual Information, Representation Learning</a>

                  </div>
                
              
            
            <div class="post-actions-wrap">
  
      <nav >
        <ul class="post-actions post-action-nav">
          
            <li class="post-action">
              
                <a class="post-action-btn btn btn--default tooltip--top" href="https://beastlyprime.github.io/mutual-information-predictive-coding-and-lipschitz-continuity/" data-tooltip="Mutual Information, Predictive Coding and Lipschitz Continuity">
              
                  <i class="fa fa-angle-left"></i>
                  <span class="hide-xs hide-sm text-small icon-ml">NEXT</span>
                </a>
            </li>
            <li class="post-action">
              
                <a class="post-action-btn btn btn--default tooltip--top" href="https://beastlyprime.github.io/your-classfier2/" data-tooltip="Your Classifier is Secretly An EBM and You Should Treat It Like One: Part 2">
              
                  <span class="hide-xs hide-sm text-small icon-mr">PREVIOUS</span>
                  <i class="fa fa-angle-right"></i>
                </a>
            </li>
          
        </ul>
      </nav>
    <ul class="post-actions post-action-share" >
      
        <li class="post-action hide-lg hide-md hide-sm">
          <a class="post-action-btn btn btn--default btn-open-shareoptions" href="#btn-open-shareoptions">
            <i class="fa fa-share-alt"></i>
          </a>
        </li>
        
          <li class="post-action hide-xs">
            <a class="post-action-btn btn btn--default" target="new" href="https://twitter.com/intent/tweet?text=https://beastlyprime.github.io/representation-learning/">
              <i class="fa fa-twitter"></i>
            </a>
          </li>
        
      
      
        <li class="post-action">
          <a class="post-action-btn btn btn--default" href="#disqus_thread">
            <i class="fa fa-comment-o"></i>
          </a>
        </li>
      
      <li class="post-action">
        
          <a class="post-action-btn btn btn--default" href="#">
        
          <i class="fa fa-list"></i>
        </a>
      </li>
    </ul>
  
</div>

            
              
                <div id="disqus_thread">
  <noscript>Please enable JavaScript to view the <a href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
</div>
              
            
          </div>
        </article>
        <footer id="footer" class="main-content-wrap">
  <span class="copyrights">
    &copy; 2022 Yimeng Chen. All Rights Reserved
  </span>
</footer>

      </div>
      <div id="bottom-bar" class="post-bottom-bar" data-behavior="1">
        <div class="post-actions-wrap">
  
      <nav >
        <ul class="post-actions post-action-nav">
          
            <li class="post-action">
              
                <a class="post-action-btn btn btn--default tooltip--top" href="https://beastlyprime.github.io/mutual-information-predictive-coding-and-lipschitz-continuity/" data-tooltip="Mutual Information, Predictive Coding and Lipschitz Continuity">
              
                  <i class="fa fa-angle-left"></i>
                  <span class="hide-xs hide-sm text-small icon-ml">NEXT</span>
                </a>
            </li>
            <li class="post-action">
              
                <a class="post-action-btn btn btn--default tooltip--top" href="https://beastlyprime.github.io/your-classfier2/" data-tooltip="Your Classifier is Secretly An EBM and You Should Treat It Like One: Part 2">
              
                  <span class="hide-xs hide-sm text-small icon-mr">PREVIOUS</span>
                  <i class="fa fa-angle-right"></i>
                </a>
            </li>
          
        </ul>
      </nav>
    <ul class="post-actions post-action-share" >
      
        <li class="post-action hide-lg hide-md hide-sm">
          <a class="post-action-btn btn btn--default btn-open-shareoptions" href="#btn-open-shareoptions">
            <i class="fa fa-share-alt"></i>
          </a>
        </li>
        
          <li class="post-action hide-xs">
            <a class="post-action-btn btn btn--default" target="new" href="https://twitter.com/intent/tweet?text=https://beastlyprime.github.io/representation-learning/">
              <i class="fa fa-twitter"></i>
            </a>
          </li>
        
      
      
        <li class="post-action">
          <a class="post-action-btn btn btn--default" href="#disqus_thread">
            <i class="fa fa-comment-o"></i>
          </a>
        </li>
      
      <li class="post-action">
        
          <a class="post-action-btn btn btn--default" href="#">
        
          <i class="fa fa-list"></i>
        </a>
      </li>
    </ul>
  
</div>

      </div>
      <div id="share-options-bar" class="share-options-bar" data-behavior="1">
  <i id="btn-close-shareoptions" class="fa fa-close"></i>
  <ul class="share-options">
    
      <li class="share-option">
        <a class="share-option-btn" target="new" href="https://twitter.com/intent/tweet?text=https%3A%2F%2Fbeastlyprime.github.io%2Frepresentation-learning%2F">
          <i class="fa fa-twitter"></i><span>Share on Twitter</span>
        </a>
      </li>
    
  </ul>
</div>
<div id="share-options-mask" class="share-options-mask"></div>
    </div>
    
    <div id="about">
  <div id="about-card">
    <div id="about-btn-close">
      <i class="fa fa-remove"></i>
    </div>
    
      <img id="about-card-picture" src="https://beastlyprime.github.io/images/author.jpg" alt="Author&#39;s picture" />
    
    <h4 id="about-card-name">Yimeng Chen</h4>
    
      <div id="about-card-bio">A bird in the forest of AI.</div>
    
    
    
      <div id="about-card-job">
        <a class="fa fa-envelope" href="mailto:chenyimeng@amss.ac.cn;chenyimeng16@icloud.com"></a>
        <br/>
      </div>
    
    
      <div id="about-card-location">
        <a class="fa fa-facebook" href="https://www.facebook.com/profile.php?id=100009746146719"></a>
        <br/>
      </div>
    
    
  </div>
</div>

    

    
  
    
      <div id="cover" style="background-image:url('https://beastlyprime.github.io/images/cover.jpg');"></div>
    
  


    
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/2.2.4/jquery.min.js" integrity="sha256-BbhdlvQf/xTY9gja0Dq3HiwQF8LaCRTXxZKRutelT44=" crossorigin="anonymous"></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js" integrity="sha256-/BfiIkHlHoVihZdc6TFuj7MmJ0TWcWsMXkeDFwhi0zw=" crossorigin="anonymous"></script>

<script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/2.1.7/js/jquery.fancybox.min.js" integrity="sha256-GEAnjcTqVP+vBp3SSc8bEDQqvWAZMiHyUSIorrWwH50=" crossorigin="anonymous"></script>


<script src="https://beastlyprime.github.io/js/script-pcw6v3xilnxydl1vddzazdverrnn9ctynvnxgwho987mfyqkuylcb1nlt.min.js"></script>


<script lang="javascript">
window.onload = updateMinWidth;
window.onresize = updateMinWidth;
document.getElementById("sidebar").addEventListener("transitionend", updateMinWidth);
function updateMinWidth() {
  var sidebar = document.getElementById("sidebar");
  var main = document.getElementById("main");
  main.style.minWidth = "";
  var w1 = getComputedStyle(main).getPropertyValue("min-width");
  var w2 = getComputedStyle(sidebar).getPropertyValue("width");
  var w3 = getComputedStyle(sidebar).getPropertyValue("left");
  main.style.minWidth = `calc(${w1} - ${w2} - ${w3})`;
}
</script>

<script>
$(document).ready(function() {
  hljs.configure({ classPrefix: '', useBR: false });
  $('pre.code-highlight > code, pre > code').each(function(i, block) {
    if (!$(this).hasClass('codeblock')) {
      $(this).addClass('codeblock');
    }
    hljs.highlightBlock(block);
  });
});
</script>


  
    
      <script>
        var disqus_config = function () {
          this.page.url = 'https:\/\/beastlyprime.github.io\/representation-learning\/';
          
            this.page.identifier = '\/representation-learning\/'
          
        };
        (function() {
          
          
          if (window.location.hostname == "localhost") {
            return;
          }
          var d = document, s = d.createElement('script');
          var disqus_shortname = 'hugo-tranquilpeak-theme';
          s.src = '//' + disqus_shortname + '.disqus.com/embed.js';

          s.setAttribute('data-timestamp', +new Date());
          (d.head || d.body).appendChild(s);
        })();
      </script>
    
  


  <script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-AMS_CHTML-full" integrity="sha256-GhM+5JHb6QUzOQPXSJLEWP7R73CbkisjzK5Eyij4U9w=" crossorigin="anonymous"></script>
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      CommonHTML: { linebreaks: { automatic: true } },
      tex2jax: { inlineMath: [ ['$', '$'], ['\\(','\\)'] ], displayMath: [ ['$$','$$'], ['\\[', '\\]'] ], processEscapes: false },
      messageStyle: 'none'
    });
  </script>



    
  </body>
</html>

